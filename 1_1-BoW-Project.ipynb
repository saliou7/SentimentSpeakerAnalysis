{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import codecs\n",
    "import re\n",
    "import os.path\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_curve, auc, roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, train_test_split, StratifiedKFold\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.feature_selection import chi2\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Données reconnaissance du locuteur (Chirac/Mitterrand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "# Chargement des données:\n",
    "def load_pres(fname):\n",
    "    alltxts = []\n",
    "    alllabs_pres = []\n",
    "    s=codecs.open(fname, 'r','utf-8') # pour régler le codage\n",
    "    while True:\n",
    "        txt = s.readline()\n",
    "        if(len(txt))<5:\n",
    "            break\n",
    "        #\n",
    "        lab = re.sub(r\"<[0-9]*:[0-9]*:(.)>.*\",\"\\\\1\",txt)\n",
    "        txt = re.sub(r\"<[0-9]*:[0-9]*:.>(.*)\",\"\\\\1\",txt)\n",
    "        if lab.count('M') >0:\n",
    "            alllabs_pres.append(-1)\n",
    "        else: \n",
    "            alllabs_pres.append(1)\n",
    "        alltxts.append(txt)\n",
    "    s.close() \n",
    "    return alltxts,alllabs_pres\n",
    "\n",
    "def load_pres_test(fname):\n",
    "    alltxts = []\n",
    "    s=codecs.open(fname, 'r','utf-8') # pour régler le codage\n",
    "    while True:\n",
    "        txt = s.readline()\n",
    "        if(len(txt))<5:\n",
    "            break\n",
    "        #\n",
    "        txt = re.sub(r\"<[0-9]*:[0-9]>(.*)\",\"\\\\1\",txt)\n",
    "        alltxts.append(txt)\n",
    "    s.close() \n",
    "    return alltxts\n",
    "\n",
    "def save_pred_pres(pred): \n",
    "    with open('prediction_president.txt', 'w') as f:\n",
    "        for item in pred:\n",
    "            f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fname = \"./datasets/AFDpresidentutf8/corpus.tache1.learn.utf8.txt\"\n",
    "fname = \"./datasets/AFDpresidentutf8/corpus.tache1.learn.utf8.txt\"\n",
    "alltxts_pres,alllabs_pres = load_pres(fname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(alltxts_pres),len(alllabs_pres))\n",
    "print(alltxts_pres[0])\n",
    "print(alllabs_pres[0])\n",
    "print(alltxts_pres[-1])\n",
    "print(alllabs_pres[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Données classification de sentiments (films)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_movies(path2data): # 1 classe par répertoire\n",
    "    alltxts = [] # init vide\n",
    "    labs = []\n",
    "    cpt = 0\n",
    "    for cl in os.listdir(path2data): # parcours des fichiers d'un répertoire\n",
    "        for f in os.listdir(path2data+cl):\n",
    "            txt = open(path2data+cl+'/'+f).read()\n",
    "            alltxts.append(txt)\n",
    "            labs.append(cpt)\n",
    "        cpt+=1 # chg répertoire = cht classe\n",
    "        \n",
    "    return alltxts,labs\n",
    "def load_movies_test(file): # 1 classe par répertoire\n",
    "    alltxts = [] \n",
    "    #lire ligne par ligne dans le fichier test\n",
    "    with open(file) as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            alltxts.append(line)\n",
    "    return alltxts\n",
    "\n",
    "def save_pred(pred): \n",
    "    with open('prediction_movies.txt', 'w') as f:\n",
    "        for item in pred:\n",
    "            if item == 1:\n",
    "                f.write(\"P\\n\")\n",
    "            else:\n",
    "                f.write(\"N\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_test = \"./datasets/testSentiment.txt\"\n",
    "alltxtsTest = load_movies_test(path_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./datasets/movies/movies1000/\"\n",
    "alltxts,alllabs = load_movies(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(alltxts),len(alllabs))\n",
    "print(alltxts[0])\n",
    "print(alllabs[0])\n",
    "print(alltxts[-1])\n",
    "print(alllabs[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A) Transformation paramétrique du texte (pre-traitements)\n",
    "\n",
    "Vous devez tester, par exemple, les cas suivants:\n",
    "- transformation en minuscule ou pas\n",
    "- suppression de la ponctuation\n",
    "- transformation des mots entièrement en majuscule en marqueurs spécifiques\n",
    "- suppression des chiffres ou pas\n",
    "- conservation d'une partie du texte seulement (seulement la première ligne = titre, seulement la dernière ligne = résumé, ...)\n",
    "- stemming\n",
    "- ...\n",
    "\n",
    "\n",
    "Vérifier systématiquement sur un exemple ou deux le bon fonctionnement des méthodes sur deux documents (au moins un de chaque classe)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "from nltk.stem import PorterStemmer\n",
    "import unicodedata\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "def preprocess_text(text, lowercase=True, remove_punctuation=True, \n",
    "                     remove_digits=True, \n",
    "                     keep_part='full', stemming=False, lemmatize=False):\n",
    "    \"\"\"\n",
    "    Série de prétraitements au texte.\n",
    "    Parameters:\n",
    "    - text: Texte à traiter.\n",
    "    - lowercase: Si True, convertit le texte en minuscules.\n",
    "    - remove_punctuation: Si True, supprime la ponctuation.\n",
    "    - remove_digits: Si True, supprime les chiffres.\n",
    "    - keep_part: Partie du texte à conserver ('full', 'first_line', 'last_line').\n",
    "    - stemming: Si True, applique le stemming.\n",
    "\n",
    "    Returns:\n",
    "    - Texte prétraité.\n",
    "    \"\"\"\n",
    "\n",
    "    # Supprimer la ponctuation \n",
    "    if remove_punctuation:\n",
    "        p = string.punctuation\n",
    "        p += '\\n\\r\\t'  # Ajouter les retours chariot, tabulation\n",
    "        text = text.translate(str.maketrans(p, ' ' * len(p)))\n",
    "        clean_text = re.sub(r'\\s[a-z]\\s', ' ', text)\n",
    "        text = clean_text.strip()\n",
    "        text = unicodedata.normalize('NFD', text).encode('ascii', 'ignore').decode(\"utf-8\")\n",
    "    \n",
    "    # Convertir en minuscules\n",
    "    if lowercase:\n",
    "        text = text.lower()\n",
    "\n",
    "    # Supprimer les chiffres\n",
    "    if remove_digits:\n",
    "        text = re.sub('[0-9]+', '', text)  # Remplacer une séquence de chiffres par rien\n",
    "\n",
    "    # Conserver une partie spécifique du texte\n",
    "    if keep_part == 'first_line':\n",
    "        text = text.split('\\n')[0]\n",
    "    elif keep_part == 'last_line':\n",
    "        text = text.split('\\n')[-1]\n",
    "\n",
    "    # Appliquer le stemming à chaque mot du texte\n",
    "    if stemming:\n",
    "        ps = PorterStemmer()\n",
    "        words = text.split()\n",
    "        stemmed_words = [ps.stem(word) for word in words]\n",
    "        text = ' '.join(stemmed_words)\n",
    "\n",
    "    if lemmatize:\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        words = text.split()\n",
    "        lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
    "        text = ' '.join(lemmatized_words)\n",
    "\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B) Extraction du vocabulaire (BoW)\n",
    "\n",
    "- **Exploration préliminaire des jeux de données**\n",
    "    - Quelle est la taille d'origine du vocabulaire?\n",
    "    - Que reste-t-il si on ne garde que les 100 mots les plus fréquents? [word cloud]\n",
    "    - Quels sont les 100 mots dont la fréquence documentaire est la plus grande? [word cloud]\n",
    "    - Quels sont les 100 mots les plus discriminants au sens de odds ratio? [word cloud]\n",
    "    - Quelle est la distribution d'apparition des mots (Zipf)\n",
    "    - Quels sont les 100 bigrammes/trigrammes les plus fréquents?\n",
    "\n",
    "- **Variantes de BoW**\n",
    "    - TF-IDF\n",
    "    - Réduire la taille du vocabulaire (min_df, max_df, max_features)\n",
    "    - BoW binaire\n",
    "    - Bi-grams, tri-grams\n",
    "    - **Quelles performances attendre ? Quels sont les avantages et les inconvénients des ces variantes?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# A) Exploration préliminaire des jeux de données\n",
    "\n",
    "def explore_dataset(vocabulary, n_top_words=100):\n",
    "    # Taille d'origine du vocabulaire\n",
    "    print(\"Taille du vocabulaire :\", len(vocabulary))\n",
    "\n",
    "    # Word Cloud pour les 100 mots les plus fréquents\n",
    "    wordcloud_top_words = WordCloud(width=400, height=200, background_color='white').generate_from_frequencies(vocabulary)\n",
    "    \n",
    "    # Word Cloud pour les 100 mots avec la fréquence documentaire la plus grande\n",
    "    df_vocabulary = pd.DataFrame(vocabulary.items(), columns=['Mot', 'Fréquence'])\n",
    "    df_vocabulary_sorted = df_vocabulary.sort_values(by='Fréquence', ascending=False)\n",
    "    wordcloud_doc_freq = WordCloud(width=400, height=200, background_color='white').generate_from_frequencies(dict(zip(df_vocabulary_sorted['Mot'], df_vocabulary_sorted['Fréquence'])))\n",
    "\n",
    "    # # Calcul des odds ratio\n",
    "    # X = vectorizer.fit_transform(alltxts_pres)\n",
    "    # chi2_stat, _ = chi2(X, alllabs_pres)\n",
    "    # odds_ratio = np.exp(chi2_stat)\n",
    "    # df_odds_ratio = pd.DataFrame({'Mot': vectorizer.get_feature_names_out(), 'Odds Ratio': odds_ratio})\n",
    "    # return df_odds_ratio\n",
    "    # df_odds_ratio_sorted = df_odds_ratio.sort_values(by='Odds Ratio', ascending=False)\n",
    "\n",
    "    # # Word Cloud pour les 100 mots les plus discriminants au sens de odds ratio\n",
    "    # df_odds_ratio_sorted = df_odds_ratio.sort_values(by='Odds Ratio', ascending=False)\n",
    "\n",
    "    # # Remplacement des valeurs NaN par une chaîne de caractères\n",
    "    # df_odds_ratio_sorted['Odds Ratio'].fillna(0, inplace=True)\n",
    "\n",
    "    # wordcloud_odds_ratio = WordCloud(width=400, height=200, background_color='white').generate_from_frequencies(dict(zip(df_odds_ratio_sorted['Mot'], df_odds_ratio_sorted['Odds Ratio'])))\n",
    "\n",
    "    # Distribution d'apparition des mots (Zipf)\n",
    "    df_zipf = df_vocabulary_sorted.reset_index(drop=True)\n",
    "\n",
    "    # Création d'une figure avec 3 sous-graphiques\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(16, 3))\n",
    "\n",
    "    # Affichage des images sur les sous-graphiques\n",
    "    axes[0].imshow(wordcloud_top_words, interpolation='bilinear')\n",
    "    axes[0].axis('off')\n",
    "    axes[0].set_title('100 mots les plus fréquents')\n",
    "\n",
    "    axes[1].imshow(wordcloud_doc_freq, interpolation='bilinear')\n",
    "    axes[1].axis('off')\n",
    "    axes[1].set_title('100 mots avec la plus grande fréquence documentaire')\n",
    "\n",
    "    # axes[2].imshow(wordcloud_odds_ratio, interpolation='bilinear')\n",
    "    # axes[2].axis('off')\n",
    "    # axes[2].set_title('100 mots les plus discriminants (Odds Ratio)')\n",
    "\n",
    "    axes[2].plot(df_zipf.index + 1, df_zipf['Fréquence'], marker='o')\n",
    "    axes[2].set_xscale('log')\n",
    "    axes[2].set_yscale('log')\n",
    "    axes[2].set_title('Distribution d\\'apparition des mots (Zipf)')\n",
    "    axes[2].set_xlabel('Rang du mot')\n",
    "    axes[2].set_ylabel('Fréquence')\n",
    "\n",
    "    # Ajustement du placement des sous-graphiques\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Affichage de la figure\n",
    "    plt.show()\n",
    "\n",
    "# # B) Variantes de BoW\n",
    "\n",
    "# Vectorisation BoW\n",
    "print(\"Vectorisation BoW\")\n",
    "vectorizer = CountVectorizer(binary=True, stop_words='english')\n",
    "X_bow = vectorizer.fit_transform(alltxts)\n",
    "vocabulary_bow = dict(zip(vectorizer.get_feature_names_out(), np.asarray(X_bow.sum(axis=0)).ravel()))\n",
    "# Exploration préliminaire\n",
    "explore_dataset(vocabulary_bow)\n",
    "\n",
    "# TF-IDF\n",
    "print(\"TF-IDF\")\n",
    "vectorizer_tfidf = TfidfVectorizer(stop_words='english')\n",
    "X_tfidf = vectorizer_tfidf.fit_transform(alltxts)\n",
    "vocabulary_tfidf = dict(zip(vectorizer_tfidf.get_feature_names_out(), np.asarray(X_tfidf.sum(axis=0)).ravel()))\n",
    "# Exploration préliminaire\n",
    "explore_dataset(vocabulary_tfidf)\n",
    "\n",
    "# Réduire la taille du vocabulaire (max_features)\n",
    "print(\"taille du vocabulaire avec max_features = 100\")\n",
    "vectorizer_max_features = CountVectorizer(max_features=100)\n",
    "X_max_features = vectorizer_max_features.fit_transform(alltxts)\n",
    "vocabulary_max_features = dict(zip(vectorizer_max_features.get_feature_names_out(), np.asarray(X_max_features.sum(axis=0)).ravel()))\n",
    "# Exploration préliminaire\n",
    "explore_dataset(vocabulary_max_features)\n",
    "\n",
    "# BoW binaire\n",
    "print(\"BoW binaire\")\n",
    "vectorizer_binary = CountVectorizer(binary=True)\n",
    "X_binary = vectorizer_binary.fit_transform(alltxts)\n",
    "vocabulary_binary = dict(zip(vectorizer_binary.get_feature_names_out(), np.asarray(X_binary.sum(axis=0)).ravel()))\n",
    "# Exploration préliminaire\n",
    "explore_dataset(vocabulary_binary)\n",
    "\n",
    "# Bigrammes\n",
    "print(\"Bigrammes\")\n",
    "vectorizer_bigram = CountVectorizer(ngram_range=(1, 2))\n",
    "X_bigram = vectorizer_bigram.fit_transform(alltxts)\n",
    "vocabulary_bigram = dict(zip(vectorizer_bigram.get_feature_names_out(), np.asarray(X_bigram.sum(axis=0)).ravel()))\n",
    "# Exploration préliminaire\n",
    "explore_dataset(vocabulary_bigram)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Analyse avec un Tfidf Binaire des données Movie Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluer_modele(vectorizer, grid_search, X_test, y_test, labels):\n",
    "    # best model\n",
    "    best_model = grid_search.best_estimator_\n",
    "    print(\"Meilleur modèle : \", best_model)\n",
    "    \n",
    "    # Obtenir les prédictions de classification du meilleur estimateur\n",
    "    y_pred = best_model.predict(X_test)\n",
    "\n",
    "    # Obtenir les prédictions de probabilité du meilleur estimateur\n",
    "    # y_proba = best_model.predict_proba(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Précision sur l'ensemble de test avec le meilleur modèle : {accuracy:.3f}\\n\")\n",
    "\n",
    "    # Matrice de confusion\n",
    "    conf_mat = confusion_matrix(y_test, y_pred)\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues', cbar=False, ax=ax)\n",
    "    ax.set_xlabel('Prédit')\n",
    "    ax.set_ylabel('Vrai')\n",
    "    ax.set_title('Matrice de confusion')\n",
    "    ax.xaxis.set_ticklabels(labels)\n",
    "    ax.yaxis.set_ticklabels(labels)\n",
    "    plt.show()\n",
    "\n",
    "    # Rapport de classification\n",
    "    print(classification_report(y_test, y_pred, target_names=labels))\n",
    "\n",
    "    # Courbe ROC\n",
    "    decision_scores = best_model.decision_function(X_test)  # scores de décision\n",
    "    # y_pred_proba = 1 / (1 + np.exp(-decision_scores)) # probabilités prédites pour utiliser dans la courbe ROC\n",
    "\n",
    "    # Calculer les taux de vrais positifs et de faux positifs\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, decision_scores)\n",
    "    # Calculer l'AUC\n",
    "    auc = roc_auc_score(y_test, decision_scores)\n",
    "    # fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "    # roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % auc)\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('Taux de faux positifs')\n",
    "    plt.ylabel('Taux de vrais positifs')\n",
    "    plt.title('Courbe ROC')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()\n",
    "\n",
    "    # Interprétation des poids\n",
    "    # Poids des mots\n",
    "    weights = grid_search.best_estimator_.coef_.flatten()\n",
    "    words = vectorizer.get_feature_names_out()\n",
    "    df_weights = pd.DataFrame({'Mot': words, 'Poids': weights})\n",
    "    df_weights_sorted = df_weights.sort_values(by='Poids', ascending=False)\n",
    "\n",
    "    # 10 mots les plus positifs\n",
    "    print(\"10 mots les plus positifs\\n\")\n",
    "    print(df_weights_sorted.head(10))\n",
    "\n",
    "    # 10 mots les plus négatifs\n",
    "    print(\"10 mots les plus négatifs\\n\")\n",
    "    print(df_weights_sorted.tail(10))\n",
    "\n",
    "    # Visualisation des poids\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 7))\n",
    "\n",
    "    # Premier sous-graphique : Barplot\n",
    "    df_weights_sorted = df_weights_sorted.head(20).append(df_weights_sorted.tail(20))\n",
    "    sns.barplot(x='Poids', y='Mot', data=df_weights_sorted, ax=axes[0])\n",
    "    axes[0].set_title('Poids des mots - Barplot')\n",
    "\n",
    "    # Deuxième sous-graphique : Word Cloud\n",
    "    wordcloud_weights = WordCloud(width=300, height=300, background_color='white').generate_from_frequencies(dict(zip(df_weights['Mot'], df_weights['Poids'])))\n",
    "    axes[1].imshow(wordcloud_weights, interpolation='bilinear')\n",
    "    axes[1].axis('off')\n",
    "    axes[1].set_title('Poids des mots - Word Cloud')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    # Visualisation des poids avec Word Cloud (positifs et négatifs)\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 7))\n",
    "\n",
    "    # Premier sous-graphique : Word Cloud (positifs)\n",
    "    df_weights_pos = df_weights_sorted[df_weights_sorted['Poids'] > 0]\n",
    "    wordcloud_weights_pos = WordCloud(width=300, height=300, background_color='white').generate_from_frequencies(dict(zip(df_weights_pos['Mot'], df_weights_pos['Poids'])))\n",
    "    axes[0].imshow(wordcloud_weights_pos, interpolation='bilinear')\n",
    "    axes[0].axis('off')\n",
    "    axes[0].set_title('Poids des mots (positifs)')\n",
    "\n",
    "    # Deuxième sous-graphique : Word Cloud (négatifs)\n",
    "    df_weights_neg = df_weights_sorted[df_weights_sorted['Poids'] < 0]\n",
    "    wordcloud_weights_neg = WordCloud(width=300, height=300, background_color='white').generate_from_frequencies(dict(zip(df_weights_neg['Mot'], df_weights_neg['Poids'])))\n",
    "    axes[1].imshow(wordcloud_weights_neg, interpolation='bilinear')\n",
    "    axes[1].axis('off')\n",
    "    axes[1].set_title('Poids des mots (négatifs)')\n",
    "\n",
    "    # plt.show()\n",
    "    return y_pred, df_weights_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alltxts_process_stem = [preprocess_text(txt, stemming=True) for txt in alltxts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "# visualisation des mots les plus fréquents en fonction de la classe\n",
    "vectorizer_binary_neg = TfidfVectorizer(stop_words=stopwords.words('english'), ngram_range=(1, 2), min_df=2, max_features=100)\n",
    "X_binary_neg = vectorizer_binary_neg.fit_transform(alltxts_process_stem[:1000])\n",
    "print(vectorizer_binary_neg.get_feature_names_out()[:20])\n",
    "vocabulary_binary_neg = dict(zip(vectorizer_binary_neg.get_feature_names_out(), np.asarray(X_binary_neg.sum(axis=0)).ravel()))\n",
    "explore_dataset(vocabulary_binary_neg)\n",
    "\n",
    "vectorizer_binary_pos = TfidfVectorizer(stop_words=stopwords.words('english'), ngram_range=(1, 2), min_df=2, max_features=100)\n",
    "X_binary_pos = vectorizer_binary_pos.fit_transform(alltxts_process_stem[1000:])\n",
    "print(vectorizer_binary_pos.get_feature_names_out()[:20])\n",
    "vocabulary_binary_pos = dict(zip(vectorizer_binary_pos.get_feature_names_out(), np.asarray(X_binary_pos.sum(axis=0)).ravel()))\n",
    "explore_dataset(vocabulary_binary_pos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "keep_words = {'couldn', 'don', 'couldn', 'didn', 'not', 'wasn'}\n",
    "l_stop_words = stop_words - keep_words\n",
    "l_stop_words = list(l_stop_words)\n",
    "\n",
    "vectorizer = CountVectorizer(binary=True, stop_words=l_stop_words, ngram_range=(1, 2), min_df=2, max_features=12500)\n",
    "X = vectorizer.fit_transform(alltxts_process_stem)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Ignore all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Split des données\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, alllabs, test_size=0.2,shuffle=True)\n",
    "# _, X_test, _, y_test = train_test_split(X, alllabs, test_size=0.2,shuffle=True)\n",
    "\n",
    "# Modèles\n",
    "models = {\n",
    "    # 'Naive Bayes': MultinomialNB(),\n",
    "    'Régression logistique': LogisticRegression(),\n",
    "    'SVC linéaire': LinearSVC()\n",
    "}\n",
    "\n",
    "# Recherche des hyperparamètres optimaux\n",
    "param_grid = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    if name == 'Naive Bayes': # le naïf bayésien n'a pas de paramètres à optimiser\n",
    "        param_grid = {\n",
    "            'alpha': [0.1]\n",
    "        }\n",
    "    elif name == 'SVC linéaire':\n",
    "        param_grid = {\n",
    "            'C': [0.1, 1, 2, 3, 5, 10],\n",
    "            'penalty': ['l2'],\n",
    "        }\n",
    "    elif name == 'Régression logistique':\n",
    "        param_grid = {\n",
    "            'C': [0.1, 1, 2, 5, 10],\n",
    "            'penalty': ['l2'],\n",
    "            'solver': ['liblinear']\n",
    "        }\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=5)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    print(f\"Meilleur score de validation croisée pour {name}: {grid_search.best_score_:.3f}\")\n",
    "    print(f\"Meilleurs hyperparamètres pour {name}: {grid_search.best_params_}\\n\")\n",
    "\n",
    "\n",
    "# Évaluation du modèle\n",
    "prediction, df = evaluer_modele(vectorizer, grid_search, X_test, y_test, ['positif', 'négatif'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(binary=True, stop_words=l_stop_words, ngram_range=(1, 2), min_df=2, max_features=12500)\n",
    "X_Test = vectorizer.fit_transform(testSentiment_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = grid_search.predict(X_Test)\n",
    "save_pred(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifieur aléatoire\n",
    "y_pred_random = np.random.choice([0, 1], size=len(y_test))\n",
    "accuracy_random = accuracy_score(y_test, y_pred_random)\n",
    "print(f\"Précision sur l'ensemble de test avec un classifieur aléatoire: {accuracy_random:.3f}\")\n",
    "print(classification_report(y_test, y_pred_random, target_names=['Négatif', 'Positif']))\n",
    "\n",
    "# Classifieur majoritaire\n",
    "y_pred_majority = np.ones(len(y_test))\n",
    "accuracy_majority = accuracy_score(y_test, y_pred_majority)\n",
    "print(f\"Précision sur l'ensemble de test avec un classifieur majoritaire: {accuracy_majority:.3f}\")\n",
    "print(classification_report(y_test, y_pred_majority, target_names=['Négatif', 'Positif']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Métriques d'évaluation \n",
    "\n",
    "Il faudra utiliser des métriques d'évaluation pertinentes suivant la tâche et l'équilibrage des données : \n",
    "- Accuracy\n",
    "- Courbe ROC, AUC, F1-score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C) Modèles de Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Variantes sur les stratégies d'entraînement\n",
    "\n",
    "- **Sur-apprentissage**. Les techniques sur lesquelles nous travaillons étant sujettes au sur-apprentissage: trouver le paramètre de régularisation dans la documentation et optimiser ce paramètre au sens de la métrique qui vous semble la plus appropriée (cf question précédente).\n",
    "<br>\n",
    "- **Equilibrage des données**. Un problème reconnu comme dur dans la communauté est celui de l'équilibrage des classes (*balance* en anglais). Que faire si les données sont à 80, 90 ou 99% dans une des classes?\n",
    "Le problème est dur mais fréquent; les solutions sont multiples mais on peut isoler 3 grandes familles de solution.\n",
    "\n",
    "1. Ré-équilibrer le jeu de données: supprimer des données dans la classe majoritaire et/ou sur-échantilloner la classe minoritaire.<BR>\n",
    "   $\\Rightarrow$ A vous de jouer pour cette technique\n",
    "1. Changer la formulation de la fonction de coût pour pénaliser plus les erreurs dans la classe minoritaire:\n",
    "soit une fonction $\\Delta$ mesurant les écarts entre $f(x_i)$ et $y_i$ \n",
    "$$C = \\sum_i  \\alpha_i \\Delta(f(x_i),y_i), \\qquad \\alpha_i = \\left\\{\n",
    "\\begin{array}{ll}\n",
    "1 & \\text{si } y_i \\in \\text{classe majoritaire}\\\\\n",
    "B>1 & \\text{si } y_i \\in \\text{classe minoritaire}\\\\\n",
    "\\end{array} \\right.$$\n",
    "<BR>\n",
    "   $\\Rightarrow$ Les SVM et d'autres approches sklearn possèdent des arguments pour régler $B$ ou $1/B$... Ces arguments sont utiles mais pas toujours suffisant.\n",
    "1. Courbe ROC et modification du biais. Une fois la fonction $\\hat y = f(x)$ apprise, il est possible de la *bidouiller* a posteriori: si toutes les prédictions $\\hat y$ sont dans une classe, on va introduire $b$ dans $\\hat y = f(x) + b$ et le faire varier jusqu'à ce qu'un des points change de classe. On peut ensuite aller de plus en plus loin.\n",
    "Le calcul de l'ensemble des scores associés à cette approche mène directement à la courbe ROC.\n",
    "\n",
    "**Note:** certains classifieurs sont intrinsèquement plus résistante au problème d'équilibrage, c'est par exemple le cas des techniques de gradient boosting que vous verrez l'an prochain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Post-processing sur les données Président\n",
    "\n",
    "Pour la tâche de reconnaissance de locuteur, des phrases successives sont souvent associés à un même locuteur. Voir par exemples les 100 premiers labels de la base d'apprentissage. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse des données president "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### variante 1 :  Utilisation de Bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_alltxts = [preprocess_text(txt, lowercase=False, stemming=True) for txt in alltxts_pres]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "# visualisation des mots les plus fréquents en fonction de la classe negative\n",
    "\n",
    "y_indice_C = np.where(np.array(alllabs_pres)==-1)[0]\n",
    "y_indice_M = np.where(np.array(alllabs_pres)==1)[0]\n",
    "\n",
    "stopwords_list = stopwords.words('french')\n",
    "vectorizer_binary_neg = TfidfVectorizer(stop_words=stopwords_list, ngram_range=(1, 2), min_df=2, max_features=200)\n",
    "X_c = vectorizer_binary_neg.fit_transform([process_alltxts[i] for i in y_indice_C])\n",
    "print(vectorizer_binary_neg.get_feature_names_out()[:20])\n",
    "vocabulary_binary_neg = dict(zip(vectorizer_binary_neg.get_feature_names_out(), np.asarray(X_c.sum(axis=0)).ravel()))\n",
    "explore_dataset(vocabulary_binary_neg)\n",
    "\n",
    "# visualisation des mots les plus fréquents en fonction de la classe positive\n",
    "vectorizer_binary_pos = TfidfVectorizer(stop_words=stopwords_list, ngram_range=(1, 2), min_df=2, max_features=200)\n",
    "X_m = vectorizer_binary_pos.fit_transform([process_alltxts[i] for i in y_indice_M])\n",
    "print(vectorizer_binary_pos.get_feature_names_out()[:20])\n",
    "vocabulary_binary_pos = dict(zip(vectorizer_binary_pos.get_feature_names_out(), np.asarray(X_m.sum(axis=0)).ravel()))\n",
    "explore_dataset(vocabulary_binary_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_list = stopwords.words('french')\n",
    "vectorizer = TfidfVectorizer(stop_words=stopwords_list, ngram_range=(1,2), min_df=1, max_df=0.95, max_features=25000)\n",
    "X = vectorizer.fit_transform(process_alltxts)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import TomekLinks\n",
    "from imblearn.combine import SMOTEENN # importer la méthode SMOTEENN\n",
    "# Ignore all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "# Split des données\n",
    "Skf = StratifiedKFold(n_splits=5, shuffle=False)\n",
    "\n",
    "fold_test = np.random.choice([0, 1, 2, 3, 4])\n",
    "index_test = []\n",
    "index_train = []\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(Skf.split(X, alllabs_pres)):\n",
    "    if i == fold_test:\n",
    "        index_test =  test_index.tolist()\n",
    "        index_train = train_index.tolist()  \n",
    "\n",
    "print(len(index_test), len(index_train))\n",
    "\n",
    "X_train = X[index_train]\n",
    "y_train = [alllabs_pres[i] for i in index_train]\n",
    "\n",
    "X_test = X[index_test]\n",
    "y_test = [alllabs_pres[i] for i in index_test]\n",
    "\n",
    "# Split des données\n",
    "# r0s = RandomUnderSampler() # sous-échantillonnage de la classe majoritaire\n",
    "# X_train, y_train = r0s.fit_resample(X_train, y_train)\n",
    "# X_test, y_test = r0s.fit_resample(X_test, y_test)\n",
    "\n",
    "# Trouver les indices où y_train est égal à 1\n",
    "indices_pos = np.where(np.array(y_train) == 1)[0]\n",
    "\n",
    "# shuffle que les données de train\n",
    "indices = np.arange(X_train.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "X_train = X_train[indices]\n",
    "y_train = np.array(y_train)[indices]\n",
    "\n",
    "# Calcul du nombre cible pour chaque classe\n",
    "n_majority = (np.where(np.array(y_train) == 1)[0]) # nombre d'observations de la classe majoritaire\n",
    "n_minority = (np.where(np.array(y_train) == -1)[0]) # nombre d'observations de la classe minoritaire\n",
    "n_target = (n_majority.shape[0] + n_minority.shape[0]) // 2 # nombre cible pour chaque classe\n",
    "\n",
    "# print(n_majority, n_minority, n_target)\n",
    "r10 = RandomUnderSampler(sampling_strategy = {1:n_target}) # sur-échantillonnage de la classe minoritaire\n",
    "X_train, y_train = r10.fit_resample(X_train, y_train)\n",
    "\n",
    "r10 = RandomOverSampler() # sur-échantillonnage de la classe minoritaire\n",
    "X_train, y_train = r10.fit_resample(X_train, y_train)\n",
    "\n",
    "# # Rééchantillonnage des données de train avec SMOTEENN\n",
    "# smote_enn = SMOTEENN(sampling_strategy=0.2)\n",
    "# X_train, y_train = smote_enn.fit_resample(X_train, y_train)\n",
    "\n",
    "# # Rééchantillonnage des données de train avec TomekLinks\n",
    "# rus = TomekLinks(sampling_strategy='majority') # sous-échantillonnage de la classe majoritaire\n",
    "# X_train, y_train = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "rus = RandomUnderSampler() # sous-échantillonnage de la classe majoritaire\n",
    "# X_test, y_test = rus.fit_resample(X_test, y_test)\n",
    "\n",
    "\n",
    "y_indice_C = np.where(np.array(y_test) == 1)[0]\n",
    "y_indice_M = np.where(np.array(y_test) == -1)[0]\n",
    "print(len(y_indice_C),len(y_indice_M))\n",
    "\n",
    "# Modèles\n",
    "models = {\n",
    "    'Régression logistique': LogisticRegression(),\n",
    "#     'SVM linéaire': LinearSVC(),\n",
    "#     'SVM' : SVC(gamma='auto')\n",
    "}\n",
    "\n",
    "# Recherche des hyperparamètres optimaux\n",
    "param_grid = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    if name == 'SVM linéaire':\n",
    "        param_grid = {\n",
    "            'C': [0.1, 1, 2, 3, 5, 10],\n",
    "            'penalty': ['l2', 'l1'],\n",
    "            'class_weight':[{-1:10, 1:1}]\n",
    "        }\n",
    "    elif name == 'Régression logistique':\n",
    "        param_grid = {\n",
    "            'C': [0.1, 1, 2, 5, 10],\n",
    "            'penalty': ['l2'],\n",
    "            # 'solver': ['liblinear'],\n",
    "            'class_weight': [\"balanced\"]\n",
    "        }\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=6)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    print(f\"Meilleur score de validation croisée pour {name}: {grid_search.best_score_:.3f}\")\n",
    "    print(f\"Meilleurs hyperparamètres pour {name}: {grid_search.best_params_}\\n\")\n",
    "\n",
    "\n",
    "# evaluer le modèle\n",
    "y_pred,_= evaluer_modele(vectorizer, grid_search, X_test, y_test, ['Mitterand', 'Chirac'])\n",
    "y_prob = grid_search.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"./datasets/AFDpresidentutf8/corpus.tache1.learn.utf8.txt\"\n",
    "alltxts,alllabs = load_pres(fname)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(list(range(len(alllabs[0:100]))),alllabs[0:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Une méthode de post-traitement pour améliorer les résultats consistent à lisser les résultats de la prédictions d'une phrases par les prédictions voisines, en utilisant par exemple une convolution par une filtre Gaussien. Compléter la fonction ci-dessous et tester l'impact de ce lissage sur les performances.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import gaussian\n",
    "def gaussian_smoothing(pred, size=11):\n",
    "    # LISSAGE par un filtre Gaussien de taille size - vous pouvez utiliser np.convolve\n",
    "    kernel = gaussian(size, 5)\n",
    "    kernel = kernel / kernel.sum()\n",
    "    acc = np.convolve(pred, kernel, mode='same')\n",
    "    smoothed = np.where(acc < 0.5, 1, -1)\n",
    "    return smoothed, acc\n",
    "pred_proba, pred_binaire = gaussian_smoothing(y_prob[:,0], 10)\n",
    "print(pred_proba)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Précision sur l'ensemble de test avec le meilleur modèle\n",
    "labels = ['Mitterand', 'Chirac']\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "accuracy =  accuracy_score(y_test, pred_proba)\n",
    "# pred_prob = best_model.predict_proba(X_test)\n",
    "\n",
    "print(f\"Précision sur l'ensemble de test avec le meilleur modèle : {accuracy:.3f}\\n\")\n",
    "# Matrice de confusion\n",
    "conf_mat = confusion_matrix(y_test, pred_proba)\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues', cbar=False, ax=ax)\n",
    "ax.set_xlabel('Prédit')\n",
    "ax.set_ylabel('Vrai')\n",
    "ax.set_title('Matrice de confusion')\n",
    "ax.xaxis.set_ticklabels(labels)\n",
    "ax.yaxis.set_ticklabels(labels)\n",
    "plt.show()\n",
    "# Rapport de classification\n",
    "print(classification_report(y_test, pred_proba, target_names=labels))\n",
    "# Courbe ROC\n",
    "# Calculer les taux de vrais positifs et de faux positifs\n",
    "fpr, tpr, thresholds = roc_curve(y_test,  1 - pred_binaire)\n",
    "\n",
    "# Calculer l'AUC\n",
    "auc = roc_auc_score(y_test,  1 - pred_binaire)\n",
    "\n",
    "# Tracer la courbe ROC\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % auc)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 4) Estimer les performances de généralisation d'une méthodes\n",
    "**Ce sera l'enjeu principal du projet : vous disposez d'un ensemble de données, et vous évaluerez les performances sur un ensemble de test auquel vous n'avez pas accès. Il faut donc être capable d'estimer les performances de généralisation du modèles à partir des données d'entraînement.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Avant de lancer de grandes expériences, il faut se construire une base de travail solide en étudiant les questions suivantes:\n",
    "\n",
    "- Combien de temps ça prend d'apprendre un classifieur NB/SVM/RegLog sur ces données en fonction de la taille du vocabulaire?\n",
    "- La validation croisée est-elle nécessaire? Est ce qu'on obtient les mêmes résultats avec un simple *split*?\n",
    "- La validation croisée est-elle stable? A partir de combien de fold (travailler avec différentes graines aléatoires et faire des statistiques basiques)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variante 2 : uitlisation de Doc2Vec\n",
    "#### **Avec un peu de chance on aura plus de performance 😏\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "\n",
    "# Création des documents pour Doc2Vec\n",
    "# tagged_data = [TaggedDocument(words=preprocess_text(txt, lowercase=False, remove_digits=False, lemmatize=True), tags=[str(i)]) for i, txt in enumerate(alltxts_pres)]\n",
    "\n",
    "\n",
    "# Entraînement du modèle Doc2Vec\n",
    "model = Doc2Vec(vector_size=500, window=20,               \n",
    "                min_count=5,                      \n",
    "                sample=0.01, workers=3,\n",
    "                cbow_mean=1, epochs=5)\n",
    "model.build_vocab(tagged_data)\n",
    "model.train(tagged_data, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "\n",
    "# Obtention des vecteurs de document\n",
    "X_doc2vec = [model.infer_vector(preprocess_text(txt, lowercase=False, remove_digits=False, lemmatize=True).split()) for txt in alltxts_pres]\n",
    "\n",
    "X_doc2vec = np.array(X_doc2vec)\n",
    "print(X_doc2vec.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Division des données\n",
    "Skf = StratifiedKFold(n_splits=5, shuffle=False)\n",
    "\n",
    "fold_test = np.random.choice([0, 1, 2, 3, 4])\n",
    "index_test = []\n",
    "index_train = []\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(Skf.split(X_doc2vec, alllabs_pres)):\n",
    "    if i == fold_test:\n",
    "        index_test =  test_index.tolist()\n",
    "        index_train = train_index.tolist()\n",
    "\n",
    "X_train = np.array([X_doc2vec[i] for i in index_train])\n",
    "y_train = [alllabs_pres[i] for i in index_train]\n",
    "\n",
    "X_test = np.array([X_doc2vec[i] for i in index_test])\n",
    "y_test = [alllabs_pres[i] for i in index_test]\n",
    "\n",
    "# Calcul du nombre cible pour chaque classe\n",
    "n_majority = (np.where(np.array(y_train) == 1)[0]) # nombre d'observations de la classe majoritaire\n",
    "n_minority = (np.where(np.array(y_train) == -1)[0]) # nombre d'observations de la classe minoritaire\n",
    "n_target = (n_majority.shape[0] + n_minority.shape[0]) // 2 # nombre cible pour chaque classe\n",
    "\n",
    "# print(n_majority, n_minority, n_target)\n",
    "r10 = RandomUnderSampler(sampling_strategy = {1:n_target}) # sur-échantillonnage de la classe minoritaire\n",
    "X_train, y_train = r10.fit_resample(X_train, y_train)\n",
    "\n",
    "r10 = RandomOverSampler() # sur-échantillonnage de la classe minoritaire\n",
    "X_train, y_train = r10.fit_resample(X_train, y_train)\n",
    "\n",
    "# Modèles\n",
    "models = {\n",
    "    'Régression logistique': LogisticRegression(),\n",
    "#     'SVM linéaire': LinearSVC()\n",
    "}\n",
    "\n",
    "# Recherche des hyperparamètres optimaux\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 2, 5, 10],\n",
    "    'penalty': ['l2'],\n",
    "    'solver': ['liblinear'],\n",
    "    'class_weight': [\"balanced\"]\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=4)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    print(f\"Meilleur score de validation croisée pour {name}: {grid_search.best_score_:.3f}\")\n",
    "    print(f\"Meilleurs hyperparamètres pour {name}: {grid_search.best_params_}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Évaluation du modèle\n",
    "best_model = grid_search.best_estimator_\n",
    "accuracy = best_model.score(X_test, y_test)\n",
    "print(f\"Accuracy du meilleur modèle sur l'ensemble de test: {accuracy:.3f}\")\n",
    "\n",
    "# Prédiction\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_prob = grid_search.predict_proba(X_test)\n",
    " # Rapport de classification\n",
    "print(classification_report(y_test, y_pred, target_names=[\"Mitterrand\", \"Chirac\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variante 3 :  Utilisation de Bert \n",
    "#### **je vais utiliser la librairie transformers de huggingface pour utiliser Bert et voir si on peut avoir une meilleure performance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attention : ça prend du temps enorme pour entrainer le modèle (surtout si vous n'avez pas de GPU)\n",
    "\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch\n",
    "import os\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "\n",
    "# Division des données en ensembles d'entraînement et de test\n",
    "Skf = StratifiedKFold(n_splits=5, shuffle=False)\n",
    "\n",
    "fold_test = np.random.choice([0, 1, 2, 3, 4])\n",
    "index_test = []\n",
    "index_train = []\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(Skf.split(alltxts_pres, alllabs_pres)):\n",
    "    if i == fold_test:\n",
    "        index_test =  test_index.tolist()\n",
    "        index_train = train_index.tolist()  \n",
    "\n",
    "\n",
    "X_train =np.array(alltxts_pres)[index_train]\n",
    "V = X_train.reshape(-1,1)\n",
    "y_train = [alllabs_pres[i] for i in index_train]\n",
    "r1s = RandomUnderSampler() # sous-échantillonnage de la classe majoritaire\n",
    "X_train, y_train = r0s.fit_resample(V, y_train)\n",
    "print(X_train.shape, len(y_train))\n",
    "X_train = X_train.flatten()\n",
    "print(X_train.shape, len(y_train))\n",
    "\n",
    "X_train = [str(x) for x in X_train]\n",
    "y_train = (np.array(y_train) + 1) // 2\n",
    "\n",
    "print(len(X_train), len(y_train))\n",
    "\n",
    "X_test = np.array(alltxts_pres)[index_test]\n",
    "X_test = [str(x) for x in X_test]\n",
    "y_test = [alllabs_pres[i] for i in index_test]\n",
    "y_test = (np.array(y_test) + 1) // 2\n",
    "\n",
    "# Chargement du tokenizer BERT\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Prétraitement des données d'entraînement\n",
    "train_encodings = tokenizer(X_train, truncation=True, padding=True, return_tensors='pt')\n",
    "\n",
    "# Prétraitement des données de test\n",
    "test_encodings = tokenizer(X_test, truncation=True, padding=True, return_tensors='pt')\n",
    "\n",
    "# Création des ensembles de données d'entraînement et de test\n",
    "train_inputs, train_masks, train_labels = train_encodings['input_ids'], train_encodings['attention_mask'], torch.tensor(y_train)\n",
    "test_inputs, test_masks, test_labels = test_encodings['input_ids'], test_encodings['attention_mask'], torch.tensor(y_test)\n",
    "\n",
    "# Chargement du modèle BERT\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2) # Assuming binary classification\n",
    "\n",
    "# Entraînement du modèle\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "print(\"Entraînement du modèle\")\n",
    "for epoch in range(5): # Adjust number of epochs\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    train_inputs, train_masks, train_labels = train_inputs.to(device), train_masks.to(device), train_labels.to(device)\n",
    "    train_labels = train_labels.long()\n",
    "    outputs = model(train_inputs, attention_mask=train_masks, labels=train_labels)\n",
    "    loss = outputs.loss\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f\"Époque {epoch + 1} terminée\")\n",
    "\n",
    "# Évaluation du modèle\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_inputs, test_masks, test_labels = test_inputs.to(device), test_masks.to(device), test_labels.to(device)\n",
    "    logits = model(test_inputs, attention_mask=test_masks).logits\n",
    "    predicted_labels = torch.argmax(logits, dim=1)\n",
    "    all_predicted_labels = predicted_labels.cpu().numpy()\n",
    "    all_true_labels = test_labels.cpu().numpy()\n",
    "\n",
    "precision = precision_score(all_true_labels, all_predicted_labels)\n",
    "recall = recall_score(all_true_labels, all_predicted_labels)\n",
    "f1 = f1_score(all_true_labels, all_predicted_labels)\n",
    "accuracy = accuracy_score(all_true_labels, all_predicted_labels)\n",
    "\n",
    "print(f\"Précision : {precision:.3f}\")\n",
    "print(f\"Rappel : {recall:.3f}\")\n",
    "print(f\"F1-score : {f1:.3f}\")\n",
    "print(f\"Accuracy : {accuracy:.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
