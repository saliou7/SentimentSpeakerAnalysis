{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import codecs\n",
    "import re\n",
    "import os.path\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_curve, auc, roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, train_test_split, StratifiedKFold\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.feature_selection import chi2\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Donn√©es reconnaissance du locuteur (Chirac/Mitterrand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "# Chargement des donn√©es:\n",
    "def load_pres(fname):\n",
    "    alltxts = []\n",
    "    alllabs_pres = []\n",
    "    s=codecs.open(fname, 'r','utf-8') # pour r√©gler le codage\n",
    "    while True:\n",
    "        txt = s.readline()\n",
    "        if(len(txt))<5:\n",
    "            break\n",
    "        #\n",
    "        lab = re.sub(r\"<[0-9]*:[0-9]*:(.)>.*\",\"\\\\1\",txt)\n",
    "        txt = re.sub(r\"<[0-9]*:[0-9]*:.>(.*)\",\"\\\\1\",txt)\n",
    "        if lab.count('M') >0:\n",
    "            alllabs_pres.append(-1)\n",
    "        else: \n",
    "            alllabs_pres.append(1)\n",
    "        alltxts.append(txt)\n",
    "    s.close() \n",
    "    return alltxts,alllabs_pres\n",
    "\n",
    "def load_pres_test(fname):\n",
    "    alltxts = []\n",
    "    s=codecs.open(fname, 'r','utf-8') # pour r√©gler le codage\n",
    "    while True:\n",
    "        txt = s.readline()\n",
    "        if(len(txt))<5:\n",
    "            break\n",
    "        #\n",
    "        txt = re.sub(r\"<[0-9]*:[0-9]>(.*)\",\"\\\\1\",txt)\n",
    "        alltxts.append(txt)\n",
    "    s.close() \n",
    "    return alltxts\n",
    "\n",
    "def save_pred_pres(pred): \n",
    "    with open('prediction_president.txt', 'w') as f:\n",
    "        for item in pred:\n",
    "            f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fname = \"./datasets/AFDpresidentutf8/corpus.tache1.learn.utf8.txt\"\n",
    "fname = \"./datasets/AFDpresidentutf8/corpus.tache1.learn.utf8.txt\"\n",
    "alltxts_pres,alllabs_pres = load_pres(fname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(alltxts_pres),len(alllabs_pres))\n",
    "print(alltxts_pres[0])\n",
    "print(alllabs_pres[0])\n",
    "print(alltxts_pres[-1])\n",
    "print(alllabs_pres[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Donn√©es classification de sentiments (films)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_movies(path2data): # 1 classe par r√©pertoire\n",
    "    alltxts = [] # init vide\n",
    "    labs = []\n",
    "    cpt = 0\n",
    "    for cl in os.listdir(path2data): # parcours des fichiers d'un r√©pertoire\n",
    "        for f in os.listdir(path2data+cl):\n",
    "            txt = open(path2data+cl+'/'+f).read()\n",
    "            alltxts.append(txt)\n",
    "            labs.append(cpt)\n",
    "        cpt+=1 # chg r√©pertoire = cht classe\n",
    "        \n",
    "    return alltxts,labs\n",
    "def load_movies_test(file): # 1 classe par r√©pertoire\n",
    "    alltxts = [] \n",
    "    #lire ligne par ligne dans le fichier test\n",
    "    with open(file) as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            alltxts.append(line)\n",
    "    return alltxts\n",
    "\n",
    "def save_pred(pred): \n",
    "    with open('prediction_movies.txt', 'w') as f:\n",
    "        for item in pred:\n",
    "            if item == 1:\n",
    "                f.write(\"P\\n\")\n",
    "            else:\n",
    "                f.write(\"N\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_test = \"./datasets/testSentiment.txt\"\n",
    "alltxtsTest = load_movies_test(path_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./datasets/movies/movies1000/\"\n",
    "alltxts,alllabs = load_movies(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(alltxts),len(alllabs))\n",
    "print(alltxts[0])\n",
    "print(alllabs[0])\n",
    "print(alltxts[-1])\n",
    "print(alllabs[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A) Transformation param√©trique du texte (pre-traitements)\n",
    "\n",
    "Vous devez tester, par exemple, les cas suivants:\n",
    "- transformation en minuscule ou pas\n",
    "- suppression de la ponctuation\n",
    "- transformation des mots enti√®rement en majuscule en marqueurs sp√©cifiques\n",
    "- suppression des chiffres ou pas\n",
    "- conservation d'une partie du texte seulement (seulement la premi√®re ligne = titre, seulement la derni√®re ligne = r√©sum√©, ...)\n",
    "- stemming\n",
    "- ...\n",
    "\n",
    "\n",
    "V√©rifier syst√©matiquement sur un exemple ou deux le bon fonctionnement des m√©thodes sur deux documents (au moins un de chaque classe)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "from nltk.stem import PorterStemmer\n",
    "import unicodedata\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "def preprocess_text(text, lowercase=True, remove_punctuation=True, \n",
    "                     remove_digits=True, \n",
    "                     keep_part='full', stemming=False, lemmatize=False):\n",
    "    \"\"\"\n",
    "    S√©rie de pr√©traitements au texte.\n",
    "    Parameters:\n",
    "    - text: Texte √† traiter.\n",
    "    - lowercase: Si True, convertit le texte en minuscules.\n",
    "    - remove_punctuation: Si True, supprime la ponctuation.\n",
    "    - remove_digits: Si True, supprime les chiffres.\n",
    "    - keep_part: Partie du texte √† conserver ('full', 'first_line', 'last_line').\n",
    "    - stemming: Si True, applique le stemming.\n",
    "\n",
    "    Returns:\n",
    "    - Texte pr√©trait√©.\n",
    "    \"\"\"\n",
    "\n",
    "    # Supprimer la ponctuation \n",
    "    if remove_punctuation:\n",
    "        p = string.punctuation\n",
    "        p += '\\n\\r\\t'  # Ajouter les retours chariot, tabulation\n",
    "        text = text.translate(str.maketrans(p, ' ' * len(p)))\n",
    "        clean_text = re.sub(r'\\s[a-z]\\s', ' ', text)\n",
    "        text = clean_text.strip()\n",
    "        text = unicodedata.normalize('NFD', text).encode('ascii', 'ignore').decode(\"utf-8\")\n",
    "    \n",
    "    # Convertir en minuscules\n",
    "    if lowercase:\n",
    "        text = text.lower()\n",
    "\n",
    "    # Supprimer les chiffres\n",
    "    if remove_digits:\n",
    "        text = re.sub('[0-9]+', '', text)  # Remplacer une s√©quence de chiffres par rien\n",
    "\n",
    "    # Conserver une partie sp√©cifique du texte\n",
    "    if keep_part == 'first_line':\n",
    "        text = text.split('\\n')[0]\n",
    "    elif keep_part == 'last_line':\n",
    "        text = text.split('\\n')[-1]\n",
    "\n",
    "    # Appliquer le stemming √† chaque mot du texte\n",
    "    if stemming:\n",
    "        ps = PorterStemmer()\n",
    "        words = text.split()\n",
    "        stemmed_words = [ps.stem(word) for word in words]\n",
    "        text = ' '.join(stemmed_words)\n",
    "\n",
    "    if lemmatize:\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        words = text.split()\n",
    "        lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
    "        text = ' '.join(lemmatized_words)\n",
    "\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B) Extraction du vocabulaire (BoW)\n",
    "\n",
    "- **Exploration pr√©liminaire des jeux de donn√©es**\n",
    "    - Quelle est la taille d'origine du vocabulaire?\n",
    "    - Que reste-t-il si on ne garde que les 100 mots les plus fr√©quents? [word cloud]\n",
    "    - Quels sont les 100 mots dont la fr√©quence documentaire est la plus grande? [word cloud]\n",
    "    - Quels sont les 100 mots les plus discriminants au sens de odds ratio? [word cloud]\n",
    "    - Quelle est la distribution d'apparition des mots (Zipf)\n",
    "    - Quels sont les 100 bigrammes/trigrammes les plus fr√©quents?\n",
    "\n",
    "- **Variantes de BoW**\n",
    "    - TF-IDF\n",
    "    - R√©duire la taille du vocabulaire (min_df, max_df, max_features)\n",
    "    - BoW binaire\n",
    "    - Bi-grams, tri-grams\n",
    "    - **Quelles performances attendre ? Quels sont les avantages et les inconv√©nients des ces variantes?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# A) Exploration pr√©liminaire des jeux de donn√©es\n",
    "\n",
    "def explore_dataset(vocabulary, n_top_words=100):\n",
    "    # Taille d'origine du vocabulaire\n",
    "    print(\"Taille du vocabulaire :\", len(vocabulary))\n",
    "\n",
    "    # Word Cloud pour les 100 mots les plus fr√©quents\n",
    "    wordcloud_top_words = WordCloud(width=400, height=200, background_color='white').generate_from_frequencies(vocabulary)\n",
    "    \n",
    "    # Word Cloud pour les 100 mots avec la fr√©quence documentaire la plus grande\n",
    "    df_vocabulary = pd.DataFrame(vocabulary.items(), columns=['Mot', 'Fr√©quence'])\n",
    "    df_vocabulary_sorted = df_vocabulary.sort_values(by='Fr√©quence', ascending=False)\n",
    "    wordcloud_doc_freq = WordCloud(width=400, height=200, background_color='white').generate_from_frequencies(dict(zip(df_vocabulary_sorted['Mot'], df_vocabulary_sorted['Fr√©quence'])))\n",
    "\n",
    "    # # Calcul des odds ratio\n",
    "    # X = vectorizer.fit_transform(alltxts_pres)\n",
    "    # chi2_stat, _ = chi2(X, alllabs_pres)\n",
    "    # odds_ratio = np.exp(chi2_stat)\n",
    "    # df_odds_ratio = pd.DataFrame({'Mot': vectorizer.get_feature_names_out(), 'Odds Ratio': odds_ratio})\n",
    "    # return df_odds_ratio\n",
    "    # df_odds_ratio_sorted = df_odds_ratio.sort_values(by='Odds Ratio', ascending=False)\n",
    "\n",
    "    # # Word Cloud pour les 100 mots les plus discriminants au sens de odds ratio\n",
    "    # df_odds_ratio_sorted = df_odds_ratio.sort_values(by='Odds Ratio', ascending=False)\n",
    "\n",
    "    # # Remplacement des valeurs NaN par une cha√Æne de caract√®res\n",
    "    # df_odds_ratio_sorted['Odds Ratio'].fillna(0, inplace=True)\n",
    "\n",
    "    # wordcloud_odds_ratio = WordCloud(width=400, height=200, background_color='white').generate_from_frequencies(dict(zip(df_odds_ratio_sorted['Mot'], df_odds_ratio_sorted['Odds Ratio'])))\n",
    "\n",
    "    # Distribution d'apparition des mots (Zipf)\n",
    "    df_zipf = df_vocabulary_sorted.reset_index(drop=True)\n",
    "\n",
    "    # Cr√©ation d'une figure avec 3 sous-graphiques\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(16, 3))\n",
    "\n",
    "    # Affichage des images sur les sous-graphiques\n",
    "    axes[0].imshow(wordcloud_top_words, interpolation='bilinear')\n",
    "    axes[0].axis('off')\n",
    "    axes[0].set_title('100 mots les plus fr√©quents')\n",
    "\n",
    "    axes[1].imshow(wordcloud_doc_freq, interpolation='bilinear')\n",
    "    axes[1].axis('off')\n",
    "    axes[1].set_title('100 mots avec la plus grande fr√©quence documentaire')\n",
    "\n",
    "    # axes[2].imshow(wordcloud_odds_ratio, interpolation='bilinear')\n",
    "    # axes[2].axis('off')\n",
    "    # axes[2].set_title('100 mots les plus discriminants (Odds Ratio)')\n",
    "\n",
    "    axes[2].plot(df_zipf.index + 1, df_zipf['Fr√©quence'], marker='o')\n",
    "    axes[2].set_xscale('log')\n",
    "    axes[2].set_yscale('log')\n",
    "    axes[2].set_title('Distribution d\\'apparition des mots (Zipf)')\n",
    "    axes[2].set_xlabel('Rang du mot')\n",
    "    axes[2].set_ylabel('Fr√©quence')\n",
    "\n",
    "    # Ajustement du placement des sous-graphiques\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Affichage de la figure\n",
    "    plt.show()\n",
    "\n",
    "# # B) Variantes de BoW\n",
    "\n",
    "# Vectorisation BoW\n",
    "print(\"Vectorisation BoW\")\n",
    "vectorizer = CountVectorizer(binary=True, stop_words='english')\n",
    "X_bow = vectorizer.fit_transform(alltxts)\n",
    "vocabulary_bow = dict(zip(vectorizer.get_feature_names_out(), np.asarray(X_bow.sum(axis=0)).ravel()))\n",
    "# Exploration pr√©liminaire\n",
    "explore_dataset(vocabulary_bow)\n",
    "\n",
    "# TF-IDF\n",
    "print(\"TF-IDF\")\n",
    "vectorizer_tfidf = TfidfVectorizer(stop_words='english')\n",
    "X_tfidf = vectorizer_tfidf.fit_transform(alltxts)\n",
    "vocabulary_tfidf = dict(zip(vectorizer_tfidf.get_feature_names_out(), np.asarray(X_tfidf.sum(axis=0)).ravel()))\n",
    "# Exploration pr√©liminaire\n",
    "explore_dataset(vocabulary_tfidf)\n",
    "\n",
    "# R√©duire la taille du vocabulaire (max_features)\n",
    "print(\"taille du vocabulaire avec max_features = 100\")\n",
    "vectorizer_max_features = CountVectorizer(max_features=100)\n",
    "X_max_features = vectorizer_max_features.fit_transform(alltxts)\n",
    "vocabulary_max_features = dict(zip(vectorizer_max_features.get_feature_names_out(), np.asarray(X_max_features.sum(axis=0)).ravel()))\n",
    "# Exploration pr√©liminaire\n",
    "explore_dataset(vocabulary_max_features)\n",
    "\n",
    "# BoW binaire\n",
    "print(\"BoW binaire\")\n",
    "vectorizer_binary = CountVectorizer(binary=True)\n",
    "X_binary = vectorizer_binary.fit_transform(alltxts)\n",
    "vocabulary_binary = dict(zip(vectorizer_binary.get_feature_names_out(), np.asarray(X_binary.sum(axis=0)).ravel()))\n",
    "# Exploration pr√©liminaire\n",
    "explore_dataset(vocabulary_binary)\n",
    "\n",
    "# Bigrammes\n",
    "print(\"Bigrammes\")\n",
    "vectorizer_bigram = CountVectorizer(ngram_range=(1, 2))\n",
    "X_bigram = vectorizer_bigram.fit_transform(alltxts)\n",
    "vocabulary_bigram = dict(zip(vectorizer_bigram.get_feature_names_out(), np.asarray(X_bigram.sum(axis=0)).ravel()))\n",
    "# Exploration pr√©liminaire\n",
    "explore_dataset(vocabulary_bigram)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Analyse avec un Tfidf Binaire des donn√©es Movie Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluer_modele(vectorizer, grid_search, X_test, y_test, labels):\n",
    "    # best model\n",
    "    best_model = grid_search.best_estimator_\n",
    "    print(\"Meilleur mod√®le : \", best_model)\n",
    "    \n",
    "    # Obtenir les pr√©dictions de classification du meilleur estimateur\n",
    "    y_pred = best_model.predict(X_test)\n",
    "\n",
    "    # Obtenir les pr√©dictions de probabilit√© du meilleur estimateur\n",
    "    # y_proba = best_model.predict_proba(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Pr√©cision sur l'ensemble de test avec le meilleur mod√®le : {accuracy:.3f}\\n\")\n",
    "\n",
    "    # Matrice de confusion\n",
    "    conf_mat = confusion_matrix(y_test, y_pred)\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues', cbar=False, ax=ax)\n",
    "    ax.set_xlabel('Pr√©dit')\n",
    "    ax.set_ylabel('Vrai')\n",
    "    ax.set_title('Matrice de confusion')\n",
    "    ax.xaxis.set_ticklabels(labels)\n",
    "    ax.yaxis.set_ticklabels(labels)\n",
    "    plt.show()\n",
    "\n",
    "    # Rapport de classification\n",
    "    print(classification_report(y_test, y_pred, target_names=labels))\n",
    "\n",
    "    # Courbe ROC\n",
    "    decision_scores = best_model.decision_function(X_test)  # scores de d√©cision\n",
    "    # y_pred_proba = 1 / (1 + np.exp(-decision_scores)) # probabilit√©s pr√©dites pour utiliser dans la courbe ROC\n",
    "\n",
    "    # Calculer les taux de vrais positifs et de faux positifs\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, decision_scores)\n",
    "    # Calculer l'AUC\n",
    "    auc = roc_auc_score(y_test, decision_scores)\n",
    "    # fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "    # roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % auc)\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('Taux de faux positifs')\n",
    "    plt.ylabel('Taux de vrais positifs')\n",
    "    plt.title('Courbe ROC')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()\n",
    "\n",
    "    # Interpr√©tation des poids\n",
    "    # Poids des mots\n",
    "    weights = grid_search.best_estimator_.coef_.flatten()\n",
    "    words = vectorizer.get_feature_names_out()\n",
    "    df_weights = pd.DataFrame({'Mot': words, 'Poids': weights})\n",
    "    df_weights_sorted = df_weights.sort_values(by='Poids', ascending=False)\n",
    "\n",
    "    # 10 mots les plus positifs\n",
    "    print(\"10 mots les plus positifs\\n\")\n",
    "    print(df_weights_sorted.head(10))\n",
    "\n",
    "    # 10 mots les plus n√©gatifs\n",
    "    print(\"10 mots les plus n√©gatifs\\n\")\n",
    "    print(df_weights_sorted.tail(10))\n",
    "\n",
    "    # Visualisation des poids\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 7))\n",
    "\n",
    "    # Premier sous-graphique : Barplot\n",
    "    df_weights_sorted = df_weights_sorted.head(20).append(df_weights_sorted.tail(20))\n",
    "    sns.barplot(x='Poids', y='Mot', data=df_weights_sorted, ax=axes[0])\n",
    "    axes[0].set_title('Poids des mots - Barplot')\n",
    "\n",
    "    # Deuxi√®me sous-graphique : Word Cloud\n",
    "    wordcloud_weights = WordCloud(width=300, height=300, background_color='white').generate_from_frequencies(dict(zip(df_weights['Mot'], df_weights['Poids'])))\n",
    "    axes[1].imshow(wordcloud_weights, interpolation='bilinear')\n",
    "    axes[1].axis('off')\n",
    "    axes[1].set_title('Poids des mots - Word Cloud')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    # Visualisation des poids avec Word Cloud (positifs et n√©gatifs)\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 7))\n",
    "\n",
    "    # Premier sous-graphique : Word Cloud (positifs)\n",
    "    df_weights_pos = df_weights_sorted[df_weights_sorted['Poids'] > 0]\n",
    "    wordcloud_weights_pos = WordCloud(width=300, height=300, background_color='white').generate_from_frequencies(dict(zip(df_weights_pos['Mot'], df_weights_pos['Poids'])))\n",
    "    axes[0].imshow(wordcloud_weights_pos, interpolation='bilinear')\n",
    "    axes[0].axis('off')\n",
    "    axes[0].set_title('Poids des mots (positifs)')\n",
    "\n",
    "    # Deuxi√®me sous-graphique : Word Cloud (n√©gatifs)\n",
    "    df_weights_neg = df_weights_sorted[df_weights_sorted['Poids'] < 0]\n",
    "    wordcloud_weights_neg = WordCloud(width=300, height=300, background_color='white').generate_from_frequencies(dict(zip(df_weights_neg['Mot'], df_weights_neg['Poids'])))\n",
    "    axes[1].imshow(wordcloud_weights_neg, interpolation='bilinear')\n",
    "    axes[1].axis('off')\n",
    "    axes[1].set_title('Poids des mots (n√©gatifs)')\n",
    "\n",
    "    # plt.show()\n",
    "    return y_pred, df_weights_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alltxts_process_stem = [preprocess_text(txt, stemming=True) for txt in alltxts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "# visualisation des mots les plus fr√©quents en fonction de la classe\n",
    "vectorizer_binary_neg = TfidfVectorizer(stop_words=stopwords.words('english'), ngram_range=(1, 2), min_df=2, max_features=100)\n",
    "X_binary_neg = vectorizer_binary_neg.fit_transform(alltxts_process_stem[:1000])\n",
    "print(vectorizer_binary_neg.get_feature_names_out()[:20])\n",
    "vocabulary_binary_neg = dict(zip(vectorizer_binary_neg.get_feature_names_out(), np.asarray(X_binary_neg.sum(axis=0)).ravel()))\n",
    "explore_dataset(vocabulary_binary_neg)\n",
    "\n",
    "vectorizer_binary_pos = TfidfVectorizer(stop_words=stopwords.words('english'), ngram_range=(1, 2), min_df=2, max_features=100)\n",
    "X_binary_pos = vectorizer_binary_pos.fit_transform(alltxts_process_stem[1000:])\n",
    "print(vectorizer_binary_pos.get_feature_names_out()[:20])\n",
    "vocabulary_binary_pos = dict(zip(vectorizer_binary_pos.get_feature_names_out(), np.asarray(X_binary_pos.sum(axis=0)).ravel()))\n",
    "explore_dataset(vocabulary_binary_pos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "keep_words = {'couldn', 'don', 'couldn', 'didn', 'not', 'wasn'}\n",
    "l_stop_words = stop_words - keep_words\n",
    "l_stop_words = list(l_stop_words)\n",
    "\n",
    "vectorizer = CountVectorizer(binary=True, stop_words=l_stop_words, ngram_range=(1, 2), min_df=2, max_features=12500)\n",
    "X = vectorizer.fit_transform(alltxts_process_stem)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Ignore all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Split des donn√©es\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, alllabs, test_size=0.2,shuffle=True)\n",
    "# _, X_test, _, y_test = train_test_split(X, alllabs, test_size=0.2,shuffle=True)\n",
    "\n",
    "# Mod√®les\n",
    "models = {\n",
    "    # 'Naive Bayes': MultinomialNB(),\n",
    "    'R√©gression logistique': LogisticRegression(),\n",
    "    'SVC lin√©aire': LinearSVC()\n",
    "}\n",
    "\n",
    "# Recherche des hyperparam√®tres optimaux\n",
    "param_grid = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    if name == 'Naive Bayes': # le na√Øf bay√©sien n'a pas de param√®tres √† optimiser\n",
    "        param_grid = {\n",
    "            'alpha': [0.1]\n",
    "        }\n",
    "    elif name == 'SVC lin√©aire':\n",
    "        param_grid = {\n",
    "            'C': [0.1, 1, 2, 3, 5, 10],\n",
    "            'penalty': ['l2'],\n",
    "        }\n",
    "    elif name == 'R√©gression logistique':\n",
    "        param_grid = {\n",
    "            'C': [0.1, 1, 2, 5, 10],\n",
    "            'penalty': ['l2'],\n",
    "            'solver': ['liblinear']\n",
    "        }\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=5)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    print(f\"Meilleur score de validation crois√©e pour {name}: {grid_search.best_score_:.3f}\")\n",
    "    print(f\"Meilleurs hyperparam√®tres pour {name}: {grid_search.best_params_}\\n\")\n",
    "\n",
    "\n",
    "# √âvaluation du mod√®le\n",
    "prediction, df = evaluer_modele(vectorizer, grid_search, X_test, y_test, ['positif', 'n√©gatif'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(binary=True, stop_words=l_stop_words, ngram_range=(1, 2), min_df=2, max_features=12500)\n",
    "X_Test = vectorizer.fit_transform(testSentiment_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = grid_search.predict(X_Test)\n",
    "save_pred(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifieur al√©atoire\n",
    "y_pred_random = np.random.choice([0, 1], size=len(y_test))\n",
    "accuracy_random = accuracy_score(y_test, y_pred_random)\n",
    "print(f\"Pr√©cision sur l'ensemble de test avec un classifieur al√©atoire: {accuracy_random:.3f}\")\n",
    "print(classification_report(y_test, y_pred_random, target_names=['N√©gatif', 'Positif']))\n",
    "\n",
    "# Classifieur majoritaire\n",
    "y_pred_majority = np.ones(len(y_test))\n",
    "accuracy_majority = accuracy_score(y_test, y_pred_majority)\n",
    "print(f\"Pr√©cision sur l'ensemble de test avec un classifieur majoritaire: {accuracy_majority:.3f}\")\n",
    "print(classification_report(y_test, y_pred_majority, target_names=['N√©gatif', 'Positif']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) M√©triques d'√©valuation \n",
    "\n",
    "Il faudra utiliser des m√©triques d'√©valuation pertinentes suivant la t√¢che et l'√©quilibrage des donn√©es : \n",
    "- Accuracy\n",
    "- Courbe ROC, AUC, F1-score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C) Mod√®les de Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Variantes sur les strat√©gies d'entra√Ænement\n",
    "\n",
    "- **Sur-apprentissage**. Les techniques sur lesquelles nous travaillons √©tant sujettes au sur-apprentissage: trouver le param√®tre de r√©gularisation dans la documentation et optimiser ce param√®tre au sens de la m√©trique qui vous semble la plus appropri√©e (cf question pr√©c√©dente).\n",
    "<br>\n",
    "- **Equilibrage des donn√©es**. Un probl√®me reconnu comme dur dans la communaut√© est celui de l'√©quilibrage des classes (*balance* en anglais). Que faire si les donn√©es sont √† 80, 90 ou 99% dans une des classes?\n",
    "Le probl√®me est dur mais fr√©quent; les solutions sont multiples mais on peut isoler 3 grandes familles de solution.\n",
    "\n",
    "1. R√©-√©quilibrer le jeu de donn√©es: supprimer des donn√©es dans la classe majoritaire et/ou sur-√©chantilloner la classe minoritaire.<BR>\n",
    "   $\\Rightarrow$ A vous de jouer pour cette technique\n",
    "1. Changer la formulation de la fonction de co√ªt pour p√©naliser plus les erreurs dans la classe minoritaire:\n",
    "soit une fonction $\\Delta$ mesurant les √©carts entre $f(x_i)$ et $y_i$ \n",
    "$$C = \\sum_i  \\alpha_i \\Delta(f(x_i),y_i), \\qquad \\alpha_i = \\left\\{\n",
    "\\begin{array}{ll}\n",
    "1 & \\text{si } y_i \\in \\text{classe majoritaire}\\\\\n",
    "B>1 & \\text{si } y_i \\in \\text{classe minoritaire}\\\\\n",
    "\\end{array} \\right.$$\n",
    "<BR>\n",
    "   $\\Rightarrow$ Les SVM et d'autres approches sklearn poss√®dent des arguments pour r√©gler $B$ ou $1/B$... Ces arguments sont utiles mais pas toujours suffisant.\n",
    "1. Courbe ROC et modification du biais. Une fois la fonction $\\hat y = f(x)$ apprise, il est possible de la *bidouiller* a posteriori: si toutes les pr√©dictions $\\hat y$ sont dans une classe, on va introduire $b$ dans $\\hat y = f(x) + b$ et le faire varier jusqu'√† ce qu'un des points change de classe. On peut ensuite aller de plus en plus loin.\n",
    "Le calcul de l'ensemble des scores associ√©s √† cette approche m√®ne directement √† la courbe ROC.\n",
    "\n",
    "**Note:** certains classifieurs sont intrins√®quement plus r√©sistante au probl√®me d'√©quilibrage, c'est par exemple le cas des techniques de gradient boosting que vous verrez l'an prochain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Post-processing sur les donn√©es Pr√©sident\n",
    "\n",
    "Pour la t√¢che de reconnaissance de locuteur, des phrases successives sont souvent associ√©s √† un m√™me locuteur. Voir par exemples les 100 premiers labels de la base d'apprentissage. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse des donn√©es president "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### variante 1 :  Utilisation de Bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_alltxts = [preprocess_text(txt, lowercase=False, stemming=True) for txt in alltxts_pres]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "# visualisation des mots les plus fr√©quents en fonction de la classe negative\n",
    "\n",
    "y_indice_C = np.where(np.array(alllabs_pres)==-1)[0]\n",
    "y_indice_M = np.where(np.array(alllabs_pres)==1)[0]\n",
    "\n",
    "stopwords_list = stopwords.words('french')\n",
    "vectorizer_binary_neg = TfidfVectorizer(stop_words=stopwords_list, ngram_range=(1, 2), min_df=2, max_features=200)\n",
    "X_c = vectorizer_binary_neg.fit_transform([process_alltxts[i] for i in y_indice_C])\n",
    "print(vectorizer_binary_neg.get_feature_names_out()[:20])\n",
    "vocabulary_binary_neg = dict(zip(vectorizer_binary_neg.get_feature_names_out(), np.asarray(X_c.sum(axis=0)).ravel()))\n",
    "explore_dataset(vocabulary_binary_neg)\n",
    "\n",
    "# visualisation des mots les plus fr√©quents en fonction de la classe positive\n",
    "vectorizer_binary_pos = TfidfVectorizer(stop_words=stopwords_list, ngram_range=(1, 2), min_df=2, max_features=200)\n",
    "X_m = vectorizer_binary_pos.fit_transform([process_alltxts[i] for i in y_indice_M])\n",
    "print(vectorizer_binary_pos.get_feature_names_out()[:20])\n",
    "vocabulary_binary_pos = dict(zip(vectorizer_binary_pos.get_feature_names_out(), np.asarray(X_m.sum(axis=0)).ravel()))\n",
    "explore_dataset(vocabulary_binary_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_list = stopwords.words('french')\n",
    "vectorizer = TfidfVectorizer(stop_words=stopwords_list, ngram_range=(1,2), min_df=1, max_df=0.95, max_features=25000)\n",
    "X = vectorizer.fit_transform(process_alltxts)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import TomekLinks\n",
    "from imblearn.combine import SMOTEENN # importer la m√©thode SMOTEENN\n",
    "# Ignore all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "# Split des donn√©es\n",
    "Skf = StratifiedKFold(n_splits=5, shuffle=False)\n",
    "\n",
    "fold_test = np.random.choice([0, 1, 2, 3, 4])\n",
    "index_test = []\n",
    "index_train = []\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(Skf.split(X, alllabs_pres)):\n",
    "    if i == fold_test:\n",
    "        index_test =  test_index.tolist()\n",
    "        index_train = train_index.tolist()  \n",
    "\n",
    "print(len(index_test), len(index_train))\n",
    "\n",
    "X_train = X[index_train]\n",
    "y_train = [alllabs_pres[i] for i in index_train]\n",
    "\n",
    "X_test = X[index_test]\n",
    "y_test = [alllabs_pres[i] for i in index_test]\n",
    "\n",
    "# Split des donn√©es\n",
    "# r0s = RandomUnderSampler() # sous-√©chantillonnage de la classe majoritaire\n",
    "# X_train, y_train = r0s.fit_resample(X_train, y_train)\n",
    "# X_test, y_test = r0s.fit_resample(X_test, y_test)\n",
    "\n",
    "# Trouver les indices o√π y_train est √©gal √† 1\n",
    "indices_pos = np.where(np.array(y_train) == 1)[0]\n",
    "\n",
    "# shuffle que les donn√©es de train\n",
    "indices = np.arange(X_train.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "X_train = X_train[indices]\n",
    "y_train = np.array(y_train)[indices]\n",
    "\n",
    "# Calcul du nombre cible pour chaque classe\n",
    "n_majority = (np.where(np.array(y_train) == 1)[0]) # nombre d'observations de la classe majoritaire\n",
    "n_minority = (np.where(np.array(y_train) == -1)[0]) # nombre d'observations de la classe minoritaire\n",
    "n_target = (n_majority.shape[0] + n_minority.shape[0]) // 2 # nombre cible pour chaque classe\n",
    "\n",
    "# print(n_majority, n_minority, n_target)\n",
    "r10 = RandomUnderSampler(sampling_strategy = {1:n_target}) # sur-√©chantillonnage de la classe minoritaire\n",
    "X_train, y_train = r10.fit_resample(X_train, y_train)\n",
    "\n",
    "r10 = RandomOverSampler() # sur-√©chantillonnage de la classe minoritaire\n",
    "X_train, y_train = r10.fit_resample(X_train, y_train)\n",
    "\n",
    "# # R√©√©chantillonnage des donn√©es de train avec SMOTEENN\n",
    "# smote_enn = SMOTEENN(sampling_strategy=0.2)\n",
    "# X_train, y_train = smote_enn.fit_resample(X_train, y_train)\n",
    "\n",
    "# # R√©√©chantillonnage des donn√©es de train avec TomekLinks\n",
    "# rus = TomekLinks(sampling_strategy='majority') # sous-√©chantillonnage de la classe majoritaire\n",
    "# X_train, y_train = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "rus = RandomUnderSampler() # sous-√©chantillonnage de la classe majoritaire\n",
    "# X_test, y_test = rus.fit_resample(X_test, y_test)\n",
    "\n",
    "\n",
    "y_indice_C = np.where(np.array(y_test) == 1)[0]\n",
    "y_indice_M = np.where(np.array(y_test) == -1)[0]\n",
    "print(len(y_indice_C),len(y_indice_M))\n",
    "\n",
    "# Mod√®les\n",
    "models = {\n",
    "    'R√©gression logistique': LogisticRegression(),\n",
    "#     'SVM lin√©aire': LinearSVC(),\n",
    "#     'SVM' : SVC(gamma='auto')\n",
    "}\n",
    "\n",
    "# Recherche des hyperparam√®tres optimaux\n",
    "param_grid = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    if name == 'SVM lin√©aire':\n",
    "        param_grid = {\n",
    "            'C': [0.1, 1, 2, 3, 5, 10],\n",
    "            'penalty': ['l2', 'l1'],\n",
    "            'class_weight':[{-1:10, 1:1}]\n",
    "        }\n",
    "    elif name == 'R√©gression logistique':\n",
    "        param_grid = {\n",
    "            'C': [0.1, 1, 2, 5, 10],\n",
    "            'penalty': ['l2'],\n",
    "            # 'solver': ['liblinear'],\n",
    "            'class_weight': [\"balanced\"]\n",
    "        }\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=6)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    print(f\"Meilleur score de validation crois√©e pour {name}: {grid_search.best_score_:.3f}\")\n",
    "    print(f\"Meilleurs hyperparam√®tres pour {name}: {grid_search.best_params_}\\n\")\n",
    "\n",
    "\n",
    "# evaluer le mod√®le\n",
    "y_pred,_= evaluer_modele(vectorizer, grid_search, X_test, y_test, ['Mitterand', 'Chirac'])\n",
    "y_prob = grid_search.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"./datasets/AFDpresidentutf8/corpus.tache1.learn.utf8.txt\"\n",
    "alltxts,alllabs = load_pres(fname)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(list(range(len(alllabs[0:100]))),alllabs[0:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Une m√©thode de post-traitement pour am√©liorer les r√©sultats consistent √† lisser les r√©sultats de la pr√©dictions d'une phrases par les pr√©dictions voisines, en utilisant par exemple une convolution par une filtre Gaussien. Compl√©ter la fonction ci-dessous et tester l'impact de ce lissage sur les performances.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import gaussian\n",
    "def gaussian_smoothing(pred, size=11):\n",
    "    # LISSAGE par un filtre Gaussien de taille size - vous pouvez utiliser np.convolve\n",
    "    kernel = gaussian(size, 5)\n",
    "    kernel = kernel / kernel.sum()\n",
    "    acc = np.convolve(pred, kernel, mode='same')\n",
    "    smoothed = np.where(acc < 0.5, 1, -1)\n",
    "    return smoothed, acc\n",
    "pred_proba, pred_binaire = gaussian_smoothing(y_prob[:,0], 10)\n",
    "print(pred_proba)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pr√©cision sur l'ensemble de test avec le meilleur mod√®le\n",
    "labels = ['Mitterand', 'Chirac']\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "accuracy =  accuracy_score(y_test, pred_proba)\n",
    "# pred_prob = best_model.predict_proba(X_test)\n",
    "\n",
    "print(f\"Pr√©cision sur l'ensemble de test avec le meilleur mod√®le : {accuracy:.3f}\\n\")\n",
    "# Matrice de confusion\n",
    "conf_mat = confusion_matrix(y_test, pred_proba)\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues', cbar=False, ax=ax)\n",
    "ax.set_xlabel('Pr√©dit')\n",
    "ax.set_ylabel('Vrai')\n",
    "ax.set_title('Matrice de confusion')\n",
    "ax.xaxis.set_ticklabels(labels)\n",
    "ax.yaxis.set_ticklabels(labels)\n",
    "plt.show()\n",
    "# Rapport de classification\n",
    "print(classification_report(y_test, pred_proba, target_names=labels))\n",
    "# Courbe ROC\n",
    "# Calculer les taux de vrais positifs et de faux positifs\n",
    "fpr, tpr, thresholds = roc_curve(y_test,  1 - pred_binaire)\n",
    "\n",
    "# Calculer l'AUC\n",
    "auc = roc_auc_score(y_test,  1 - pred_binaire)\n",
    "\n",
    "# Tracer la courbe ROC\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % auc)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 4) Estimer les performances de g√©n√©ralisation d'une m√©thodes\n",
    "**Ce sera l'enjeu principal du projet : vous disposez d'un ensemble de donn√©es, et vous √©valuerez les performances sur un ensemble de test auquel vous n'avez pas acc√®s. Il faut donc √™tre capable d'estimer les performances de g√©n√©ralisation du mod√®les √† partir des donn√©es d'entra√Ænement.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Avant de lancer de grandes exp√©riences, il faut se construire une base de travail solide en √©tudiant les questions suivantes:\n",
    "\n",
    "- Combien de temps √ßa prend d'apprendre un classifieur NB/SVM/RegLog sur ces donn√©es en fonction de la taille du vocabulaire?\n",
    "- La validation crois√©e est-elle n√©cessaire? Est ce qu'on obtient les m√™mes r√©sultats avec un simple *split*?\n",
    "- La validation crois√©e est-elle stable? A partir de combien de fold (travailler avec diff√©rentes graines al√©atoires et faire des statistiques basiques)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variante 2 : uitlisation de Doc2Vec\n",
    "#### **Avec un peu de chance on aura plus de performance üòè\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "\n",
    "# Cr√©ation des documents pour Doc2Vec\n",
    "# tagged_data = [TaggedDocument(words=preprocess_text(txt, lowercase=False, remove_digits=False, lemmatize=True), tags=[str(i)]) for i, txt in enumerate(alltxts_pres)]\n",
    "\n",
    "\n",
    "# Entra√Ænement du mod√®le Doc2Vec\n",
    "model = Doc2Vec(vector_size=500, window=20,               \n",
    "                min_count=5,                      \n",
    "                sample=0.01, workers=3,\n",
    "                cbow_mean=1, epochs=5)\n",
    "model.build_vocab(tagged_data)\n",
    "model.train(tagged_data, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "\n",
    "# Obtention des vecteurs de document\n",
    "X_doc2vec = [model.infer_vector(preprocess_text(txt, lowercase=False, remove_digits=False, lemmatize=True).split()) for txt in alltxts_pres]\n",
    "\n",
    "X_doc2vec = np.array(X_doc2vec)\n",
    "print(X_doc2vec.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Division des donn√©es\n",
    "Skf = StratifiedKFold(n_splits=5, shuffle=False)\n",
    "\n",
    "fold_test = np.random.choice([0, 1, 2, 3, 4])\n",
    "index_test = []\n",
    "index_train = []\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(Skf.split(X_doc2vec, alllabs_pres)):\n",
    "    if i == fold_test:\n",
    "        index_test =  test_index.tolist()\n",
    "        index_train = train_index.tolist()\n",
    "\n",
    "X_train = np.array([X_doc2vec[i] for i in index_train])\n",
    "y_train = [alllabs_pres[i] for i in index_train]\n",
    "\n",
    "X_test = np.array([X_doc2vec[i] for i in index_test])\n",
    "y_test = [alllabs_pres[i] for i in index_test]\n",
    "\n",
    "# Calcul du nombre cible pour chaque classe\n",
    "n_majority = (np.where(np.array(y_train) == 1)[0]) # nombre d'observations de la classe majoritaire\n",
    "n_minority = (np.where(np.array(y_train) == -1)[0]) # nombre d'observations de la classe minoritaire\n",
    "n_target = (n_majority.shape[0] + n_minority.shape[0]) // 2 # nombre cible pour chaque classe\n",
    "\n",
    "# print(n_majority, n_minority, n_target)\n",
    "r10 = RandomUnderSampler(sampling_strategy = {1:n_target}) # sur-√©chantillonnage de la classe minoritaire\n",
    "X_train, y_train = r10.fit_resample(X_train, y_train)\n",
    "\n",
    "r10 = RandomOverSampler() # sur-√©chantillonnage de la classe minoritaire\n",
    "X_train, y_train = r10.fit_resample(X_train, y_train)\n",
    "\n",
    "# Mod√®les\n",
    "models = {\n",
    "    'R√©gression logistique': LogisticRegression(),\n",
    "#     'SVM lin√©aire': LinearSVC()\n",
    "}\n",
    "\n",
    "# Recherche des hyperparam√®tres optimaux\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 2, 5, 10],\n",
    "    'penalty': ['l2'],\n",
    "    'solver': ['liblinear'],\n",
    "    'class_weight': [\"balanced\"]\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=4)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    print(f\"Meilleur score de validation crois√©e pour {name}: {grid_search.best_score_:.3f}\")\n",
    "    print(f\"Meilleurs hyperparam√®tres pour {name}: {grid_search.best_params_}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# √âvaluation du mod√®le\n",
    "best_model = grid_search.best_estimator_\n",
    "accuracy = best_model.score(X_test, y_test)\n",
    "print(f\"Accuracy du meilleur mod√®le sur l'ensemble de test: {accuracy:.3f}\")\n",
    "\n",
    "# Pr√©diction\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_prob = grid_search.predict_proba(X_test)\n",
    " # Rapport de classification\n",
    "print(classification_report(y_test, y_pred, target_names=[\"Mitterrand\", \"Chirac\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variante 3 :  Utilisation de Bert \n",
    "#### **je vais utiliser la librairie transformers de huggingface pour utiliser Bert et voir si on peut avoir une meilleure performance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attention : √ßa prend du temps enorme pour entrainer le mod√®le (surtout si vous n'avez pas de GPU)\n",
    "\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch\n",
    "import os\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "\n",
    "# Division des donn√©es en ensembles d'entra√Ænement et de test\n",
    "Skf = StratifiedKFold(n_splits=5, shuffle=False)\n",
    "\n",
    "fold_test = np.random.choice([0, 1, 2, 3, 4])\n",
    "index_test = []\n",
    "index_train = []\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(Skf.split(alltxts_pres, alllabs_pres)):\n",
    "    if i == fold_test:\n",
    "        index_test =  test_index.tolist()\n",
    "        index_train = train_index.tolist()  \n",
    "\n",
    "\n",
    "X_train =np.array(alltxts_pres)[index_train]\n",
    "V = X_train.reshape(-1,1)\n",
    "y_train = [alllabs_pres[i] for i in index_train]\n",
    "r1s = RandomUnderSampler() # sous-√©chantillonnage de la classe majoritaire\n",
    "X_train, y_train = r0s.fit_resample(V, y_train)\n",
    "print(X_train.shape, len(y_train))\n",
    "X_train = X_train.flatten()\n",
    "print(X_train.shape, len(y_train))\n",
    "\n",
    "X_train = [str(x) for x in X_train]\n",
    "y_train = (np.array(y_train) + 1) // 2\n",
    "\n",
    "print(len(X_train), len(y_train))\n",
    "\n",
    "X_test = np.array(alltxts_pres)[index_test]\n",
    "X_test = [str(x) for x in X_test]\n",
    "y_test = [alllabs_pres[i] for i in index_test]\n",
    "y_test = (np.array(y_test) + 1) // 2\n",
    "\n",
    "# Chargement du tokenizer BERT\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Pr√©traitement des donn√©es d'entra√Ænement\n",
    "train_encodings = tokenizer(X_train, truncation=True, padding=True, return_tensors='pt')\n",
    "\n",
    "# Pr√©traitement des donn√©es de test\n",
    "test_encodings = tokenizer(X_test, truncation=True, padding=True, return_tensors='pt')\n",
    "\n",
    "# Cr√©ation des ensembles de donn√©es d'entra√Ænement et de test\n",
    "train_inputs, train_masks, train_labels = train_encodings['input_ids'], train_encodings['attention_mask'], torch.tensor(y_train)\n",
    "test_inputs, test_masks, test_labels = test_encodings['input_ids'], test_encodings['attention_mask'], torch.tensor(y_test)\n",
    "\n",
    "# Chargement du mod√®le BERT\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2) # Assuming binary classification\n",
    "\n",
    "# Entra√Ænement du mod√®le\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "print(\"Entra√Ænement du mod√®le\")\n",
    "for epoch in range(5): # Adjust number of epochs\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    train_inputs, train_masks, train_labels = train_inputs.to(device), train_masks.to(device), train_labels.to(device)\n",
    "    train_labels = train_labels.long()\n",
    "    outputs = model(train_inputs, attention_mask=train_masks, labels=train_labels)\n",
    "    loss = outputs.loss\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f\"√âpoque {epoch + 1} termin√©e\")\n",
    "\n",
    "# √âvaluation du mod√®le\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_inputs, test_masks, test_labels = test_inputs.to(device), test_masks.to(device), test_labels.to(device)\n",
    "    logits = model(test_inputs, attention_mask=test_masks).logits\n",
    "    predicted_labels = torch.argmax(logits, dim=1)\n",
    "    all_predicted_labels = predicted_labels.cpu().numpy()\n",
    "    all_true_labels = test_labels.cpu().numpy()\n",
    "\n",
    "precision = precision_score(all_true_labels, all_predicted_labels)\n",
    "recall = recall_score(all_true_labels, all_predicted_labels)\n",
    "f1 = f1_score(all_true_labels, all_predicted_labels)\n",
    "accuracy = accuracy_score(all_true_labels, all_predicted_labels)\n",
    "\n",
    "print(f\"Pr√©cision : {precision:.3f}\")\n",
    "print(f\"Rappel : {recall:.3f}\")\n",
    "print(f\"F1-score : {f1:.3f}\")\n",
    "print(f\"Accuracy : {accuracy:.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
